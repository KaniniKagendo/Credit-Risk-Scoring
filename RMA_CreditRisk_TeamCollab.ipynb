{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaniniKagendo/Dataset-Credit-Risk/blob/main/RMA_CreditRisk_TeamCollab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DSA 8304: RISK MANAGEMENT ANALYTICS CREDIT RISK MODELING GROUPWORK"
      ],
      "metadata": {
        "id": "CxGQJwY_AqvL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
      ],
      "metadata": {
        "id": "empzN4s8_ZD5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lXUzoZK6mGE"
      },
      "source": [
        "# Credit Risk Modeling Notebook\n",
        "\n",
        "## Introduction\n",
        "LendingClub stands as the largest peer-to-peer lending platform globally. The objective of this notebook is to delve into risk analytics within the banking and financial services sector. It aims to explore how data is employed to mitigate the potential financial losses associated with lending to customers.\n",
        "\n",
        "## Problem Statement\n",
        "LendingClub, a specialized lender for urban customers, faces the task of evaluating loan applications and making approval decisions based on applicant profiles. This decision carries two types of risks:\n",
        "\n",
        "a) Risk of Missed Business Opportunity: When an applicant is likely to repay the loan, choosing not to approve the loan would result in a loss of potential business for the company.\n",
        "\n",
        "b) Risk of Financial Loss: On the other hand, if an applicant is unlikely to repay the loan and is at high risk of defaulting, approving the loan could potentially lead to a financial loss for the company.\n",
        "\n",
        "Thus, LendingClub must carefully assess each loan application, aiming to strike a balance between maximizing business opportunities by approving loans from creditworthy applicants and minimizing the potential for financial losses resulting from defaults.\n",
        "\n",
        "This section aims to:\n",
        "- Provide an overview of the credit risk modeling problem.\n",
        "- Clearly define the problem statement and the objective of the analysis.\n",
        "- Outline the data sources and any relevant background information.\n",
        "\n",
        "## Data Understanding and Exploration\n",
        "The dataset provides information on past loan applicants and their default status. The goal is to identify patterns that indicate the probability of an applicant defaulting. This information guides decisions like loan denial, adjusting loan amounts, offering higher interest rates to risky applicants, and more.\n",
        "When individuals apply for a loan, the company can take two types of decisions:\n",
        "\n",
        "1) Loan Acceptance: If the loan is approved, three scenarios can arise:\n",
        "\n",
        "a) Fully Paid: The applicant successfully repays the loan, including principal and interest.\n",
        "\n",
        "b) Current: The applicant is currently making loan repayments, and the loan term is ongoing. They are not considered as defaulting.\n",
        "\n",
        "c) Charged-off: The applicant fails to make timely loan repayments, resulting in default.\n",
        "\n",
        "2) Loan Rejection: The company rejects the loan application if the applicant does not meet their requirements. As a result, there is no transactional history available for these applicants in the dataset.\n",
        "\n",
        "By analyzing the data, patterns can be identified to evaluate the likelihood of defaulting. This enables the company to make informed decisions regarding loan approvals, manage risk, and adjust interest rates accordingly.\n",
        "\n",
        "This section incorporates the below processes:\n",
        "- Import the necessary libraries and load the dataset.\n",
        "- Perform initial data exploration to understand the structure and characteristics of the data.\n",
        "- Handle missing values, outliers, and perform necessary data preprocessing steps.\n",
        "- Conduct descriptive statistics and visualizations to gain insights into the data through EDA.\n",
        "\n",
        "## Feature Engineering\n",
        "- Perform feature selection or creation based on domain knowledge and exploratory analysis.\n",
        "- Handle categorical variables by encoding or transforming them appropriately.\n",
        "- Scale or normalize numerical features if required.\n",
        "- Split the dataset into training and testing sets.\n",
        "\n",
        "## Model Development and Evaluation\n",
        "- Select appropriate credit risk modeling algorithms, such as logistic regression, random forests, or gradient boosting.\n",
        "- Train the selected models on the training data.\n",
        "- Evaluate model performance using suitable metrics like accuracy, precision, recall, and F1-score.\n",
        "- Fine-tune the models through hyperparameter optimization and cross-validation.\n",
        "- Compare and analyze the results of different models.\n",
        "\n",
        "## Model Interpretation\n",
        "- Interpret the trained models to understand the important features and their impact on credit risk.\n",
        "- Visualize the model results, such as feature importance, coefficients, or decision boundaries.\n",
        "\n",
        "## Model Deployment and Conclusion\n",
        "- Save the trained model for future use or deployment.\n",
        "- Summarize the findings and conclusions from the analysis.\n",
        "- Provide recommendations or insights based on the results.\n",
        "- Discuss any limitations or areas for future improvement.\n",
        "\n",
        "## References and Acknowledgments\n",
        "- List any references, data sources, or external libraries used.\n",
        "- Acknowledge any collaborators, open-source projects, or code snippets used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SwXC3FexLVg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "261800a5-e304-49ec-ee7e-3bb4bffe474e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLqQIcxbSi0j"
      },
      "source": [
        "# Loading Libraries and Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3J_llSsSd9u"
      },
      "outputs": [],
      "source": [
        "# # install package if not installed\n",
        "# !pip3 install pandas\n",
        "# !pip3 install numpy\n",
        "# !pip3 install seaborn\n",
        "# !pip3 install matplotlib\n",
        "# !pip3 install statsmodels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivy0FS2lYS_D"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import missingno as mn\n",
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nvh-Z_dbSwG0"
      },
      "outputs": [],
      "source": [
        "#accepted_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/archive/accepted_2007_to_2018q4.csv/accepted_2007_to_2018Q4.csv')\n",
        "# accepted_df = pd.read_csv('/content/accepted_2007_to_2018Q4.csv')\n",
        "accepted_df=pd.read_csv('/content/drive/MyDrive/Accepted and Rejected Loans Data RMA/accepted_2007_to_2018Q4.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc3oVjA-T5jN"
      },
      "outputs": [],
      "source": [
        "#rejected_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/archive/rejected_2007_to_2018q4.csv/rejected_2007_to_2018Q4.csv')\n",
        "# rejected_df = pd.read_csv('/content/rejected_2007_to_2018Q4.csv')\n",
        "rejected_df=pd.read_csv('/content/drive/MyDrive/Accepted and Rejected Loans Data RMA/rejected_2007_to_2018Q4.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5MbB9vRy3Wk"
      },
      "source": [
        "# Data understanding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oW7CCPpSu5AC"
      },
      "outputs": [],
      "source": [
        "# check the first 5 rows of the data\n",
        "rejected_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIZ6JbAVvb-W"
      },
      "outputs": [],
      "source": [
        "# check the last 5 rows of the data\n",
        "rejected_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XR94UnzIvJ3q"
      },
      "outputs": [],
      "source": [
        "# check the first 5 rows of the data\n",
        "accepted_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRzQeBXGvfEt"
      },
      "outputs": [],
      "source": [
        "# check the last 5 rows of the data\n",
        "accepted_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25wrCKgQv_A7"
      },
      "outputs": [],
      "source": [
        "# check the shape of the data\n",
        "rejected_df.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qW3aovqiwnbb"
      },
      "outputs": [],
      "source": [
        "# check the shape of the data\n",
        "accepted_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4HHwD8mwxU5"
      },
      "outputs": [],
      "source": [
        "# check the info of the data\n",
        "rejected_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVQy9qbWw7Fl"
      },
      "outputs": [],
      "source": [
        "# check the info of the data\n",
        "accepted_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsUIL6p9xSfe"
      },
      "outputs": [],
      "source": [
        "# check the columns of the data\n",
        "rejected_df.columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kfhiaf9txW7l"
      },
      "outputs": [],
      "source": [
        "# check the columns of the data\n",
        "accepted_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4x4UvysQxbAd"
      },
      "outputs": [],
      "source": [
        "# check the data types of the data\n",
        "rejected_df.dtypes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvGqRCrdxkbm"
      },
      "outputs": [],
      "source": [
        "# check the data types of the data\n",
        "accepted_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnaKvrmqxtGp"
      },
      "outputs": [],
      "source": [
        "# check the missing values in the data\n",
        "rejected_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oTet5GuxymU"
      },
      "outputs": [],
      "source": [
        "# check the missing values in the data\n",
        "accepted_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPDF3OjKyIVQ"
      },
      "outputs": [],
      "source": [
        "# check the unique values in the data\n",
        "rejected_df.nunique()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqPvyHwMyOVH"
      },
      "outputs": [],
      "source": [
        "# check the unique values in the data\n",
        "accepted_df.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "444XAC5KytH4"
      },
      "source": [
        "### Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qU8e_xsy0uUf"
      },
      "outputs": [],
      "source": [
        "# from accepted_df, drop member_id column because it only has null values\n",
        "accepted_df.drop('member_id', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLTJEcGY1pkJ"
      },
      "outputs": [],
      "source": [
        "# In accepted_df, drop columns with more than 50 percent missing values\n",
        "accepted_df.dropna(thresh=0.5*len(accepted_df), axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tj81CbywyyeX"
      },
      "outputs": [],
      "source": [
        "# in rejected_df, change the data type of Application Date to datetime\n",
        "rejected_df['Application Date'] = pd.to_datetime(rejected_df['Application Date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emZDgON83zrd"
      },
      "outputs": [],
      "source": [
        "# In rejedted_df, drop columns with more than 50 percent missing values\n",
        "rejected_df.dropna(thresh=0.5*len(rejected_df), axis=1, inplace=True)\n",
        "\n",
        "#@ Joe please validate this and revert by Friday. Thanks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydx7JxIw4Jqj"
      },
      "outputs": [],
      "source": [
        "accepted_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W08nNNUK4Phk"
      },
      "outputs": [],
      "source": [
        "rejected_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytOB_5gX6nXX"
      },
      "outputs": [],
      "source": [
        "rejected_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZDCEjBf5acv"
      },
      "source": [
        "https://github.com/dosei1/Lending-Club-Loan-Data/blob/master/LCDataDictionary.csv\n",
        "\n",
        "Dictionary link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1Z4nBLi5ZKY"
      },
      "outputs": [],
      "source": [
        "# Feature trimming (20 features)\n",
        "\n",
        "trim=[\"addr_state\",\"annual_inc\",\"dti\",\"emp_length\",\"fico_range_high\",\"fico_range_low\",\n",
        "     \"grade\",\"home_ownership\",\"installment\",\"int_rate\",\"loan_amnt\",\"loan_status\",\"mort_acc\",\n",
        "     \"open_acc\",\"pub_rec_bankruptcies\",\"purpose\",\"revol_util\",\"sub_grade\",\"term\",\"total_acc\"]\n",
        "\n",
        "\n",
        "accepted_trim=accepted_df[trim]\n",
        "accepted_trim.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IdFsI4S8FJH"
      },
      "outputs": [],
      "source": [
        "# Chceking the info of accepted_trim\n",
        "accepted_trim.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufQDZERO6oea"
      },
      "outputs": [],
      "source": [
        "# check for null values in accpepted_trim\n",
        "accepted_trim.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0TscPgH6qfj"
      },
      "outputs": [],
      "source": [
        "# check for null values in rejected_df\n",
        "rejected_df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WXaq-C17G0H"
      },
      "outputs": [],
      "source": [
        "# check the shape of rejected_df\n",
        "accepted_trim.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeP62ol-7WQZ"
      },
      "outputs": [],
      "source": [
        "# check the shape of accpepted_trim\n",
        "rejected_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jJEtZld_dJ4"
      },
      "outputs": [],
      "source": [
        "# check for unique values in rejected_df\n",
        "accepted_trim.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyTtpLAt_d8T"
      },
      "outputs": [],
      "source": [
        "# check for unique values in rejected_df\n",
        "rejected_df.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sujmOsM0An3e"
      },
      "source": [
        "**accepted_trim dataset:** This dataset is about approved loans from the Lending\n",
        "Club. It contains 2,260,701 entries (rows) and 20 features (columns). Here's what each column likely represents:\n",
        "\n",
        "\n",
        "\n",
        "1.   addr_state: The U.S. state of the borrower.\n",
        "2.   annual_inc: The annual income of the borrower, likely in dollars.\n",
        "\n",
        "1.   annual_inc: The annual income of the borrower, likely in dollars.\n",
        "2.   dti: Debt-to-income ratio of the borrower.\n",
        "\n",
        "5.   emp_length: Employment length of the borrower, possibly in years.\n",
        "\n",
        "1.   fico_range_high and fico_range_low: The range of FICO scores for the borrower. FICO scores are a type of credit score used by lenders to help assess credit risk.\n",
        "2.   grade and sub_grade: Lending Club's grading system for the creditworthiness of the borrower.\n",
        "2.   home_ownership: The home ownership status of the borrower (e.g., rent, own, mortgage).\n",
        "1.   installment: The monthly payment owed by the borrower.\n",
        "int_rate: The interest rate on the loan.\n",
        "1.   loan_amnt: The amount of the loan.\n",
        "2.   loan_status: The status of the loan (e.g., fully paid, charged off).\n",
        "2.   mort_acc: Number of mortgage accounts.\n",
        "1.   open_acc: Number of open credit lines in the borrower's credit file.\n",
        "1.   pub_rec_bankruptcies: Number of public record bankruptcies.\n",
        "1.   purpose: Purpose of the loan.\n",
        "2.   revol_util: Revolving line utilization rate, or the amount of credit the borrower is using relative to all available revolving credit.\n",
        "2.   term: The term of the loan (e.g., 36 months, 60 months).\n",
        "2.   total_acc: The total number of credit lines currently in the borrower's credit file.\n",
        "\n",
        "\n",
        "**rejected_df dataset**: This dataset is about loan applications that were rejected by the Lending Club. It contains 27,648,741 entries and 8 features.\n",
        "\n",
        "Here's what each column represents:\n",
        "1.   Amount Requested: The amount of the loan requested by the applicant.\n",
        "2.   Application Date: The date the loan application was submitted.\n",
        "2.   Loan Title: The title or description of the loan provided by the applicant.\n",
        "1.   Debt-To-Income Ratio: The debt-to-income ratio of the applicant.\n",
        "1.   Zip Code: The zip code of the applicant.\n",
        "2.   State: The U.S. state of the applicant\n",
        "2.   Employment Length: The length of the applicant's employment, possibly in years.\n",
        "1.   Policy Code: An internal code representing the lending policy.\n",
        "2.   List item\n",
        "\n",
        "\n",
        "\n",
        "Each dataset has a number of missing or null values in various columns. These missing values could potentially introduce bias or inaccuracies in any analysis or model built using this data, and will need to be handled appropriately during the data cleaning process.\n",
        "\n",
        "The unique values for categorical variables like addr_state or grade could represent the number of categories in the data. For numerical variables like annual_inc or loan_amnt, a high number of unique values could indicate a wide range of values, and may require further investigation to understand their distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxE02WJIArE4"
      },
      "outputs": [],
      "source": [
        "# drop rows with null values in accepted_trim and rejected_df\n",
        "accepted_trim.dropna(inplace=True)\n",
        "rejected_df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pH3C6eTLEpJw"
      },
      "outputs": [],
      "source": [
        "# Check the shape\n",
        "accepted_trim.shape\n",
        "\n",
        "# Dropped 197,263 rows with null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCxJUzTvE636"
      },
      "outputs": [],
      "source": [
        "# Check the shape\n",
        "rejected_df.shape\n",
        "\n",
        "# Dropped 953,770 rows with null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rmdAzmaFwUN"
      },
      "outputs": [],
      "source": [
        "# Check for outliers\n",
        "def remove_outliers(df):\n",
        "    for col in df.select_dtypes(include=np.number).columns.tolist():\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "        df.loc[(df[col] < lower_bound) | (df[col] > upper_bound), col] = np.nan\n",
        "    return df\n",
        "\n",
        "# Removing outliers from the dataframes\n",
        "accepted_trim = remove_outliers(accepted_trim)\n",
        "rejected_df = remove_outliers(rejected_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Szyj5oIGqoy"
      },
      "outputs": [],
      "source": [
        "accepted_trim.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uk6yQaqULWou"
      },
      "outputs": [],
      "source": [
        "def extract_term(s):\n",
        "    if isinstance(s, str):  # check if it's a string\n",
        "        return int(s.split()[0]), s.split()[1]\n",
        "    else:\n",
        "        return None, None  # handle NaN or unexpected values\n",
        "\n",
        "# Apply the function to the 'term' column\n",
        "accepted_trim['Term Number'], accepted_trim['Term Unit'] = zip(*accepted_trim['term'].map(extract_term))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avowdYkLGuLL"
      },
      "outputs": [],
      "source": [
        "rejected_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvLaylXaHrUR"
      },
      "outputs": [],
      "source": [
        "print(rejected_df['Employment Length'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvRztY-SKDZD"
      },
      "outputs": [],
      "source": [
        "def extract_employment_length(s):\n",
        "    if s == '< 1 year':\n",
        "        return 0, 'less_than_year'\n",
        "    elif s == '10+ years':\n",
        "        return 10, 'ten_or_more_years'\n",
        "    elif isinstance(s, str):  # check if it's a string\n",
        "        return int(s.split()[0]), 'exact_years'\n",
        "    else:\n",
        "        return None, None  # handle NaN or unexpected values\n",
        "\n",
        "# Apply the function to the 'Employment Length' column\n",
        "rejected_df['Employment Length Number'], rejected_df['Employment Length Context'] = zip(*rejected_df['Employment Length'].map(extract_employment_length))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJDQAJwvKSuA"
      },
      "source": [
        "The function extract_employment_length takes a string from the Employment Length column and returns a tuple with the number of years and the context. The map() function is then used to apply this function to each value in the column, and the results are unpacked into two new columns in the DataFrame.\n",
        "\n",
        "After running this code, you should have two new columns in your DataFrame: Employment Length Number, which contains the number of years of employment as an integer, and Employment Length Context, which contains the context as a string. You can then use these columns for further analysis or modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bj7FoW05HU20"
      },
      "outputs": [],
      "source": [
        "# Remove the '%' sign and convert to float\n",
        "rejected_df['Debt-To-Income Ratio'] = rejected_df['Debt-To-Income Ratio'].str.replace('%', '').astype(float)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYNKdMl3dd2D"
      },
      "outputs": [],
      "source": [
        "# drop rows with null values in accepted_trim and rejected_df\n",
        "accepted_trim.dropna(inplace=True)\n",
        "rejected_df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyyfSGhTKpZz"
      },
      "outputs": [],
      "source": [
        "accepted_trim.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5T8qrDyKtEZ"
      },
      "outputs": [],
      "source": [
        "rejected_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhdbPx3Lij2g"
      },
      "source": [
        "# Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsTzatvOcLQS"
      },
      "outputs": [],
      "source": [
        "accepted_trim.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8E3Ougic335"
      },
      "outputs": [],
      "source": [
        "rejected_df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fVcH8hUdKsY"
      },
      "source": [
        "####EDA for Accepted_trim (Approved Loans of the Lending Club)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PIVo9rn47ZQ"
      },
      "outputs": [],
      "source": [
        "# A Visualization of the distribution of the status of loans disbursed from the accepted loans\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.countplot(data=accepted_trim, x='loan_status')\n",
        "plt.title('Loan Status Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqe3hKsPWZcw"
      },
      "source": [
        "It is apparent that loans classified as \"Fully paid\" exhibit a significantly higher count in comparison to those categorized as \"Defaulted,\" thereby highlighting a notable disparity in their respective statuses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2DIrqlRa0hz"
      },
      "outputs": [],
      "source": [
        "#We can choose between the above and the below, which works for us :)\n",
        "fig, ax =plt.subplots(figsize=(10,4))\n",
        "sns.countplot(data=accepted_trim,x=\"loan_status\",hue=\"term\",palette='dark')\n",
        "ax.set(xlabel='Status', ylabel='')\n",
        "ax.set_title('Loan status distribution', size=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iGj7zUuhZn_"
      },
      "outputs": [],
      "source": [
        "accepted_trim.groupby('loan_status').describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2v4nULhhof3"
      },
      "source": [
        "From the above table, we're able to see the statistical distribution of the Loan Status variable. It is evident that there is lot of data about current loan , charged off loan and Fully paid loans."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMkTgGbq5Las"
      },
      "outputs": [],
      "source": [
        "fig, ax =plt.subplots(figsize=(10,4))\n",
        "sns.countplot(data=accepted_trim,x=\"emp_length\",palette='spring')\n",
        "ax.set(xlabel='Length of Employmnet', ylabel='')\n",
        "ax.set_title('Loan status count vs Employment length', size=20)\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6J0yatuj3fe"
      },
      "outputs": [],
      "source": [
        "accepted_trim['emp_length'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmKz6fQnW_vn"
      },
      "source": [
        "From the above illustration and summary, A clear pattern emerges wherein employees with a tenure exceeding 10 years demonstrate a distinct advantage in terms of loan accessibility compared to their counterparts with relatively shorter durations of employment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZmaUT7e6GUH"
      },
      "outputs": [],
      "source": [
        "# A Visualization of the distribution of loan amounts\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(data=accepted_trim, x='loan_amnt', kde=True, bins=30)\n",
        "plt.title('Loan Amount Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UdI3ITMXZy7"
      },
      "source": [
        "From the above visualization, a conspicuous pattern emerges, revealing a discernible prevalence of loans disbursed in the 10,000 currency unit range, surpassing the allocation of funds in the remaining loan categories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3d2q_eI_8y6g"
      },
      "outputs": [],
      "source": [
        "# A Visualization of the distribution of interest rates\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(data=accepted_trim, x='int_rate', kde=True, bins=30)\n",
        "plt.title('Interest Rate Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuJEPeAjdkNQ"
      },
      "source": [
        "Based on the visual analysis presented above, it appears that loans with a 15% interest rate have exhibited the highest disbursal frequency throughout the observed period"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HflGR3W3h2Yv"
      },
      "outputs": [],
      "source": [
        "#Visualizing the Loan Grade Count\n",
        "fig, ax =plt.subplots(figsize=(10,4))\n",
        "sns.countplot(data=accepted_trim,y=\"grade\",palette='rocket')\n",
        "ax.set_title('Loan Grades count', size=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYGs9erCd5Nl"
      },
      "source": [
        "Upon careful observation of the  visualization, a salient inference arises, unequivocally indicating that loan grades B and C exhibit a notable predominance in terms of their count."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Y2fXnOH9AmQ"
      },
      "outputs": [],
      "source": [
        "# An Analysis of the distribution of loan amounts across different loan grades\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(data=accepted_trim, x='grade', y='loan_amnt', order=sorted(accepted_trim['grade'].unique()))\n",
        "plt.title('Loan Amount Distribution Across Loan Grades')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQFtl7_HNeXN"
      },
      "source": [
        "The above is a depiction of the distribution of loan amounts as compared to the respective Loan grades."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_S13pATL9UZg"
      },
      "outputs": [],
      "source": [
        "#An Analysis of the distribution of interest rates across different loan grades\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(data=accepted_trim, x='grade', y='int_rate', order=sorted(accepted_trim['grade'].unique()))\n",
        "plt.title('Interest Rate Distribution Across Loan Grades')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnNxC22FW8HA"
      },
      "source": [
        "From the above visual, It looks like F and G subgrades have the highest interest rates as compared to the rest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tccYqmkISQo0"
      },
      "outputs": [],
      "source": [
        "#An Analysis of the distribution of annual incomes\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(data=accepted_trim[accepted_trim['annual_inc'] < 300000], x='annual_inc', kde=True, bins=30)\n",
        "plt.title('Annual Income Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTMieoQJeJw8"
      },
      "source": [
        "From the above visual, the loanees with the annual income of 50,000 have access to the most loans than their counterparts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zok5GzI_WGw4"
      },
      "outputs": [],
      "source": [
        "#An Analysis the distribution of debt-to-income ratios\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(data=accepted_trim, x='dti', kde=True, bins=30)\n",
        "plt.title('Debt-to-Income Ratio Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfW7daDWiCb1"
      },
      "source": [
        "This discernibly illustrates that when an individual's debt-to-income ratio is elevated, there is a greater likelihood of loan default in the presence of higher interest rates. It seems that the smaller the dti the more likely that the loan will not be paid."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfmX7Zi_iUC-"
      },
      "outputs": [],
      "source": [
        "#A Visualization of the Purpose of the loans versus the respective amounts\n",
        "fig, ax =plt.subplots(figsize=(10,4))\n",
        "sns.barplot(data=accepted_trim,x=\"purpose\",y='loan_amnt',palette='spring')\n",
        "ax.set(xlabel='Purpose', ylabel='Amount')\n",
        "ax.set_title('Purpose vs Loan_ Amount', size=20)\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ag146cMkHXN"
      },
      "outputs": [],
      "source": [
        "accepted_trim['purpose'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVNm4j0lekRh"
      },
      "source": [
        "The chart above depicts the purpose for which the loanees take up loans. It's apparent that most take loans for Debt Consolidation, small businesses, credit card settlement and housing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwIBjTO-i2M9"
      },
      "outputs": [],
      "source": [
        "#An Analysis of the Home Ownership Vs the Annual Income\n",
        "fig, ax =plt.subplots(figsize=(10,4))\n",
        "sns.barplot(data=accepted_trim,x=\"home_ownership\",y='annual_inc',palette='viridis')\n",
        "ax.set(xlabel='Home Ownership', ylabel='Annual Income')\n",
        "ax.set_title('Home Ownership vs Annual Income', size=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGbAUFkKe_tQ"
      },
      "source": [
        "In the above comparison, It is evident that loanees with a higher annual income opt for a Mortgage package when it comes to Home Ownership."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6_uFQpPXLJS"
      },
      "outputs": [],
      "source": [
        "# Analyze the distribution of loan amounts and interest rates by loan grade and loan status using violin plots\n",
        "# plt.figure(figsize=(12, 6))\n",
        "for grade in sorted(accepted_trim['grade'].unique()):\n",
        "    df_grade = accepted_trim[accepted_trim['grade'] == grade]\n",
        "    sns.violinplot(data=df_grade, x='loan_status', y='loan_amnt', inner='quartile')\n",
        "    plt.title(f'Loan Amount Distribution by Loan Status and Grade {grade}')\n",
        "    plt.xlabel('Loan Status')\n",
        "    plt.ylabel('Loan Amount (in USD)')\n",
        "    plt.show()\n",
        "\n",
        "    sns.violinplot(data=df_grade, x='loan_status', y='int_rate', inner='quartile')\n",
        "    plt.title(f'Interest Rate Distribution by Loan Status and Grade {grade}')\n",
        "    plt.xlabel('Loan Status')\n",
        "    plt.ylabel('Interest Rate')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5n4ZGFRkaaJ"
      },
      "outputs": [],
      "source": [
        "# Plotting a heatmap for the Accepted Loans\n",
        "plt.figure(figsize=(15,10))\n",
        "sns.heatmap(accepted_trim.corr(),annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfduaeHlW5TG"
      },
      "outputs": [],
      "source": [
        "#An Analysis of the correlation matrix between numerical variables\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.heatmap(accepted_trim[['annual_inc', 'dti', 'fico_range_high', 'fico_range_low', 'installment', 'int_rate', 'loan_amnt', 'mort_acc', 'open_acc', 'pub_rec_bankruptcies', 'revol_util', 'total_acc', 'Term Number']].corr(), annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Matrix of Numerical Variables')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlWfP7glWk0u"
      },
      "source": [
        "There's a strong correlation between \"loan_amnt\" the \"installment\" feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdORNq99mPE4"
      },
      "outputs": [],
      "source": [
        "# Dividing the features into categorical and numerical\n",
        "categorical=[feature for feature in accepted_trim.columns if accepted_trim[feature].dtype=='object']\n",
        "numerical=[feature for feature in accepted_trim.columns if feature not in categorical]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yywQvTHFmerq"
      },
      "outputs": [],
      "source": [
        "print(\"Categorical columns:\",categorical)\n",
        "print(\"Numerical columns:\",numerical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waAGlXKEnFQN"
      },
      "outputs": [],
      "source": [
        "# Histplot for each variable in numerical list\n",
        "def histplot_visual(data,column):\n",
        "    fig, ax = plt.subplots(3,5,figsize=(15,6))\n",
        "    fig.suptitle('Histplot for each variable',y=1, size=20)\n",
        "    ax=ax.flatten()\n",
        "    for i,feature in enumerate(column):\n",
        "        sns.histplot(data=data[feature],ax=ax[i], kde=True)\n",
        "histplot_visual(data=accepted_trim,column=numerical)\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkyi_IlXn0EF"
      },
      "outputs": [],
      "source": [
        "# Boxplot for each variable in numerical list\n",
        "def boxplots_visual(data,column):\n",
        "    fig, ax = plt.subplots(3,5,figsize=(15,6))\n",
        "    fig.suptitle('Boxplot for each variable',y=1, size=20)\n",
        "    ax=ax.flatten()\n",
        "    for i,feature in enumerate(column):\n",
        "        sns.boxplot(data=data[feature],ax=ax[i], orient='h')\n",
        "        ax[i].set_title(feature+ ', skewness is: '+str(round(data[feature].skew(axis = 0, skipna = True),2)),fontsize=10)\n",
        "        ax[i].set_xlim([min(data[feature]), max(data[feature])])\n",
        "boxplots_visual(data=accepted_trim,column=numerical)\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMYK_I2_J_jM"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAvWweR9J-04"
      },
      "outputs": [],
      "source": [
        "accepted_trim.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQSC-jMjKK5x"
      },
      "outputs": [],
      "source": [
        "accepted_trim['loan_status'].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBq1l89hKZGq"
      },
      "outputs": [],
      "source": [
        "accepted_trim['loan_status'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsOeQKgBKfpo"
      },
      "source": [
        "Setting up the target variable. We create a Loan Status Variable 'Current or Good', vs 'Default or Bad' based on values provided in the loan_status column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiurVqkTKfXO"
      },
      "outputs": [],
      "source": [
        "#Setting up the target variable 'loan_status_log'\n",
        "\n",
        "def loans_classification(string):\n",
        "    if \"Current\" in string:\n",
        "        return 1\n",
        "    elif \"Fully Paid\" in string:\n",
        "        return 1\n",
        "    elif \"In Grace Period\" in string:\n",
        "        return 1\n",
        "    elif \"Late\" in string:\n",
        "        return 0\n",
        "    elif \"Charged Off\" in string:\n",
        "        return 0\n",
        "\n",
        "accepted_trim['loan_status_log'] = accepted_trim['loan_status'].map(loans_classification)\n",
        "accepted_trim.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qsphd6PXK7_B"
      },
      "outputs": [],
      "source": [
        "accepted_trim['loan_status_log'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfcS658TLaUo"
      },
      "outputs": [],
      "source": [
        "accepted_trim['loan_status_log'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXtS18NTLqqy"
      },
      "source": [
        "Transforming the 'emp_length' variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZDUjbDyLgYS"
      },
      "outputs": [],
      "source": [
        "accepted_trim['emp_length'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dkSBcULL9Eg"
      },
      "outputs": [],
      "source": [
        "emp_length_map = {'< 1 year': 0,\n",
        "                  '1 year': 1,\n",
        "                  '2 years': 2,\n",
        "                  '3 years': 3,\n",
        "                  '4 years': 4,\n",
        "                  '5 years': 5,\n",
        "                  '6 years': 6,\n",
        "                  '7 years': 7,\n",
        "                  '8 years': 8,\n",
        "                  '9 years': 9,\n",
        "                  '10+ years': 10}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fa3erSneMA7d"
      },
      "outputs": [],
      "source": [
        "accepted_trim['emp_length'] = accepted_trim['emp_length'].apply(lambda x: emp_length_map[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKZx60FsMIo9"
      },
      "outputs": [],
      "source": [
        "accepted_trim['emp_length'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5ejtR1iMVpK"
      },
      "outputs": [],
      "source": [
        "accepted_trim.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-ZyqyBKMcw9"
      },
      "source": [
        "Variable: Purpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xesOJC-tMs3w"
      },
      "outputs": [],
      "source": [
        "accepted_trim['purpose'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36AB3qhcM5-Q"
      },
      "outputs": [],
      "source": [
        "def purpose_category(string):\n",
        "    if \"debt_consolidation\" in string:\n",
        "        return 'debt_consolidation'\n",
        "    elif \"credit_card\" in string:\n",
        "        return 'credit_card'\n",
        "    elif \"home_improvement\" in string:\n",
        "        return 'home_improvement'\n",
        "    elif \"major_purchase\" in string:\n",
        "        return 'major_purchase'\n",
        "    else:\n",
        "        return 'other'\n",
        "\n",
        "accepted_trim['purpose'] = accepted_trim['purpose'].map(purpose_category)\n",
        "accepted_trim['purpose'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqx9lBw3NGwf"
      },
      "source": [
        "One Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ln_fubZ4NOl9"
      },
      "outputs": [],
      "source": [
        "pd.get_dummies(accepted_trim[['home_ownership', 'purpose', 'grade','term']], drop_first=True).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMV54IHTNtbu"
      },
      "outputs": [],
      "source": [
        "#to dataframe\n",
        "accepted_trim_dummies = pd.get_dummies(accepted_trim[['home_ownership', 'purpose', 'grade','term']], drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bj7QboMOI8P"
      },
      "outputs": [],
      "source": [
        "accepted_trim_dummies.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIR8dYMmOuQd"
      },
      "source": [
        "Defining X and y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4fOW-8POtxe"
      },
      "outputs": [],
      "source": [
        "X = accepted_trim.drop(columns = ['addr_state', 'grade', 'loan_status', 'term', 'Term Unit', 'Term Number', 'loan_status_log', 'home_ownership', 'purpose', 'sub_grade'],axis=1)\n",
        "y = accepted_trim[['loan_status_log']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b0zdqjbO5_d"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poJIntiNPAoO"
      },
      "outputs": [],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyJMYh6QPG9s"
      },
      "outputs": [],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOvsvmd8PTvU"
      },
      "source": [
        "Scaling the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kp9NmeesPWvM"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "ss = StandardScaler()\n",
        "X_scaled = ss.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8z5tLs4WPc1t"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(X_scaled).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmSV7tUnPgdJ"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(X_scaled, columns=X.columns).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4X-7JSRZPi_-"
      },
      "outputs": [],
      "source": [
        "accepted_trim_sc = pd.DataFrame(X_scaled, columns=X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCf7aD8EPpT_"
      },
      "outputs": [],
      "source": [
        "accepted_trim_sc.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktkr1jDDPyQh"
      },
      "outputs": [],
      "source": [
        "# accepted_trim_new = pd.concat([ accepted_trim_sc, accepted_trim_dummies,], axis=1, join='inner')\n",
        "accepted_trim_new = pd.concat([accepted_trim_sc, accepted_trim_dummies.reindex(accepted_trim_sc.index)], axis=1)\n",
        "accepted_trim_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZa2SXAJP0s_"
      },
      "outputs": [],
      "source": [
        "accepted_trim_new.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irNB9K5qQAn8"
      },
      "outputs": [],
      "source": [
        "# accepted_trim_new = pd.merge(accepted_trim_dummies, accepted_trim_sc,  left_index=True, right_index=True)\n",
        "# accepted_trim_new.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eUvTJvbQEPe"
      },
      "outputs": [],
      "source": [
        "accepted_trim_new.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tgTrzp4QTfu"
      },
      "outputs": [],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIA_oxGnnrEx"
      },
      "outputs": [],
      "source": [
        "# Drop null values from y\n",
        "y.dropna(inplace=True)\n",
        "\n",
        "# Keep only the rows in accepted_trim_new whose index is present in y\n",
        "accepted_trim_new = accepted_trim_new[accepted_trim_new.index.isin(y.index)]\n",
        "\n",
        "# Keep only the rows in y whose index is present in accepted_trim_new\n",
        "y = y[y.index.isin(accepted_trim_new.index)]\n",
        "\n",
        "print(f\"Shape of y: {y.shape}\")\n",
        "print(f\"Shape of accepted_trim_new: {accepted_trim_new.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eBnVfK_G5j8"
      },
      "source": [
        "# Machine Learning Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoQKHaQMs9II"
      },
      "source": [
        "The Machine Learning Models detailed herein are:\n",
        "1. Logistic Regression\n",
        "2. Random Forest Classifier\n",
        "3. Support Vector Classifier\n",
        "4. K Nearest Neighbours\n",
        "\n",
        "\n",
        "These models leverage advanced algorithms to assess and predict creditworthiness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSwgKQhQgn_w"
      },
      "source": [
        "The Evaluation Metrics considered for testing out the accuracy of the Machine learning models were Precision, Recall and F1 Scores.\n",
        "\n",
        "Precision gives the proportion of positive identifications that were indeed correct, reflecting the model's ability to accurately pinpoint actual risky loans. It can be defined as:\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "Recall (Sensitivity) determines the proportion of real positives that were correctly identified therefore implying, a highly sensitive test accurately detects credit that carries risk. It can be defined as:\n",
        "\n",
        " ![image.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "The F1 Score proves valuable in situations where a trade-off between precision and recall is necessary. It is calculated using the following formula:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "Accuracy refers to the number of correctly predicted risks out of all the data points, providing an overall measure of the model's correctness.\n",
        "\n",
        "Since our objective is to minimize the Lending Club loss while predicting the risk of loanee default,\n",
        "\n",
        "A good Recall Rate is desirable since it seeks to identify the maximum amount of loanees that are prone to stop paying their debts, thus a small number of False Negatives is sought.\n",
        "\n",
        "A good Precision rate is useful in seeking to minimize the number of false positives, avoiding a scenario where loanees are mistakenly classified as defaulters.\n",
        "\n",
        "The Confusion Matrix comes in handy to check and visualize how the models perform on the test set and the accuracy score tests how well the models predict the loan status of the loanees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2O_NFKakWetf"
      },
      "outputs": [],
      "source": [
        "# # drop rows with null values in accepted_trim and rejected_df\n",
        "# accepted_trim.dropna(inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiv6tEGRG-ya"
      },
      "outputs": [],
      "source": [
        "# Splitting the dataset into train and test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train , X_test , y_train, y_test = train_test_split(accepted_trim_new, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Importing machine learning models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Initializing the models\n",
        "lr = LogisticRegression()\n",
        "svc = SVC()\n",
        "rfc = RandomForestClassifier()\n",
        "knn = KNeighborsClassifier()\n",
        "ln = LinearRegression()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp_s5wOeVf9k"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14e0Fky-VjEq"
      },
      "outputs": [],
      "source": [
        "# Splitting the dataset into train and test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train , X_test , y_train, y_test = train_test_split(accepted_trim_new, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initializing the model\n",
        "lr = LogisticRegression()\n",
        "\n",
        "# Logistic Regression Model\n",
        "model1 = [lr]\n",
        "\n",
        "# Function to train and evaluate the model\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "def train_and_evaluate(models, X_train, X_test, y_train, y_test):\n",
        "    for model in models:\n",
        "        # Training the model\n",
        "        model.fit(X_train, y_train.values.ravel())  # y_train.values.ravel() to avoid warnings\n",
        "        # Making predictions\n",
        "        y_pred = model.predict(X_test)\n",
        "        # Evaluating the model\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        print(f\"Model: {model.__class__.__name__}, Accuracy: {accuracy}\")\n",
        "        # Evaluate model precision\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        print(f\"Model: {model.__class__.__name__}, Precision: {precision}\")\n",
        "\n",
        "        # Evaluate model recall\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        print(f\"Model: {model.__class__.__name__}, Recall: {recall}\")\n",
        "\n",
        "        # Evaluate model F1 score\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "        print(f\"Model: {model.__class__.__name__}, F1 Score: {f1}\")\n",
        "\n",
        "        # Print confusion matrix\n",
        "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "        print(f\"Confusion Matrix: \\n{conf_matrix}\")\n",
        "\n",
        "# Running the function\n",
        "train_and_evaluate(model1, X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy: The accuracy of the model is 0.87, which means that it correctly predicts the outcome (credit risk or no credit risk) for approximately 87% of the data points.\n",
        "\n",
        "Precision: The precision of the model is also 0.87, indicating that when it predicts a loan to have credit risk, it is correct approximately 87% of the time.\n",
        "\n",
        "Recall: The recall of the model is 1.0, which means that it correctly identifies all the loans with credit risk. In other words, it does not miss any loans that actually carry risk.\n",
        "\n",
        "F1 Score: The F1 score is 0.93, which is a harmonic mean of precision and recall. It provides an overall measure of the model's performance, combining its ability to identify risky loans and the accuracy of those identifications.\n",
        "\n",
        "Confusion Matrix: The confusion matrix shows the model's predictions against the actual values. In this case, the model predicts no loans with credit risk (0) for the entire dataset, while the actual data contains 39,842 loans with credit risk and 266,857 loans without credit risk.\n",
        "\n",
        "Based on these results, the model seems to be highly accurate and precise in identifying loans without credit risk. However, it fails to identify any loans with credit risk (possibly due to an imbalance in the dataset). Further investigation and analysis are required to determine the reasons behind this and to evaluate the model's overall performance."
      ],
      "metadata": {
        "id": "AhF0NGSjwVm7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAwlBSk7Uo_Z"
      },
      "source": [
        "###Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QG-jiH2cudgz"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Split the dataset into train and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(accepted_trim_new, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define parameter distribution\n",
        "param_dist = {\n",
        "    'n_estimators': randint(50, 200),\n",
        "    'max_features': ['auto', 'sqrt'],\n",
        "    'max_depth': randint(2, 10),\n",
        "    'min_samples_split': randint(2, 11),\n",
        "    'min_samples_leaf': randint(1, 11),\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Initialize the RandomForestClassifier\n",
        "rfc = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Create a RandomizedSearchCV object\n",
        "random_search = RandomizedSearchCV(rfc, param_distributions=param_dist, n_iter=10, cv=5, n_jobs=-1)\n",
        "\n",
        "# Train the model\n",
        "random_search.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# Print the best parameters found by RandomizedSearchCV\n",
        "print(random_search.best_params_)\n",
        "\n",
        "# Predict the test set results using the best model\n",
        "y_pred = random_search.predict(X_test)\n",
        "\n",
        "# Evaluate model accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model: {random_search.best_estimator_.__class__.__name__}, Accuracy: {accuracy}\")\n",
        "\n",
        "# Evaluate model precision\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "print(f\"Model: {random_search.best_estimator_.__class__.__name__}, Precision: {precision}\")\n",
        "\n",
        "# Evaluate model recall\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "print(f\"Model: {random_search.best_estimator_.__class__.__name__}, Recall: {recall}\")\n",
        "\n",
        "# Evaluate model F1 score\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print(f\"Model: {random_search.best_estimator_.__class__.__name__}, F1 Score: {f1}\")\n",
        "\n",
        "# Print confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(f\"Confusion Matrix: \\n{conf_matrix}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy: The accuracy of the model is 0.87, indicating that it correctly predicts the outcome (credit risk or no credit risk) for approximately 87% of the data points.\n",
        "\n",
        "Precision: The precision of the model is 0.76, meaning that when it predicts a loan to have credit risk, it is correct approximately 76% of the time.\n",
        "\n",
        "Recall: The recall of the model is also 0.87, suggesting that it identifies approximately 87% of the actual loans with credit risk.\n",
        "\n",
        "F1 Score: The F1 score is 0.81, which combines the precision and recall into a single metric. It provides an overall measure of the model's performance, balancing both the accuracy of predictions and the model's ability to identify true credit risk.\n",
        "\n",
        "Confusion Matrix: The confusion matrix displays the model's predictions against the actual values. In this case, the model predicts no loans with credit risk (0) for the entire dataset, while the actual data contains 26,508 loans with credit risk and 177,958 loans without credit risk.\n",
        "\n",
        "Based on these results, the model demonstrates a high accuracy rate, but its precision is relatively low, indicating a significant number of false positive predictions (predicting credit risk when there is none). This suggests that the model may be prone to overestimating the presence of credit risk. Further evaluation and refinement may be required to improve the precision and overall performance of the model in credit assessment tasks."
      ],
      "metadata": {
        "id": "cieXAFFvwtaT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xx4vs0OT_Hw"
      },
      "source": [
        "###Support Vector Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwqptVKiJj40"
      },
      "outputs": [],
      "source": [
        "# # Import necessary libraries\n",
        "# from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# # Split the dataset into train and test data\n",
        "# X_train, X_test, y_train, y_test = train_test_split(accepted_trim_new, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Define parameter distribution\n",
        "# param_dist = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['rbf', 'linear']}\n",
        "\n",
        "# # Initialize the SVC model\n",
        "# svc = SVC()\n",
        "\n",
        "# # Create a RandomizedSearchCV object\n",
        "# random_search = RandomizedSearchCV(svc, param_distributions=param_dist, n_iter=10, cv=5, n_jobs=-1)\n",
        "\n",
        "# # Train the model\n",
        "# random_search.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# # Print the best parameters found by RandomizedSearchCV\n",
        "# print(random_search.best_params_)\n",
        "\n",
        "# # Predict the test set results using the best model\n",
        "# y_pred = random_search.predict(X_test)\n",
        "\n",
        "# # Evaluate model accuracy\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "# print(f\"Model: {random_search.best_estimator_.__class__.__name__}, Accuracy: {accuracy}\")\n",
        "\n",
        "# # Evaluate model precision\n",
        "# precision = precision_score(y_test, y_pred, average='weighted')\n",
        "# print(f\"Model: {random_search.best_estimator_.__class__.__name__}, Precision: {precision}\")\n",
        "\n",
        "# # Evaluate model recall\n",
        "# recall = recall_score(y_test, y_pred, average='weighted')\n",
        "# print(f\"Model: {random_search.best_estimator_.__class__.__name__}, Recall: {recall}\")\n",
        "\n",
        "# # Evaluate model F1 score\n",
        "# f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "# print(f\"Model: {random_search.best_estimator_.__class__.__name__}, F1 Score: {f1}\")\n",
        "\n",
        "# # Print confusion matrix\n",
        "# conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "# print(f\"Confusion Matrix: \\n{conf_matrix}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwM-CoQ8J1aY"
      },
      "source": [
        " We first define a dictionary param_dist specifying multiple potential values for the C, gamma, and kernel parameters of SVC. Then, we initialize the SVC model and create a RandomizedSearchCV object. We provide the SVC model, the parameter distribution, specify the number of parameter settings that are sampled (n_iter), the number of folds in cross-validation (cv), and use all available CPU cores for computation (n_jobs=-1).\n",
        "\n",
        "The RandomizedSearchCV object is then fit to the training data, and we print the best parameters found. Finally, we make predictions on the test set using the best model found by RandomizedSearchCV and calculate the model accuracy.\n",
        "\n",
        "In contrast to GridSearchCV, not all parameter values are tried out, but rather a fixed number of parameter settings is sampled from the specified distributions. The number of parameter settings that are tried is given by n_iter, which is more computationally efficient than trying every single combination, especially when the number of parameters and their potential values are quite large."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVDE5gNVUuBu"
      },
      "source": [
        "### K Nearest Neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66fBb_aOLYWN"
      },
      "outputs": [],
      "source": [
        "# # Import necessary libraries\n",
        "# from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "# from sklearn.neighbors import KNeighborsClassifier\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# from scipy.stats import randint\n",
        "# from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# # Split the dataset into train and test data\n",
        "# X_train, X_test, y_train, y_test = train_test_split(accepted_trim_new, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Define parameter distribution\n",
        "# param_dist = {\n",
        "#     'n_neighbors': randint(1, 50),\n",
        "#     'weights': ['uniform', 'distance'],\n",
        "#     'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
        "#     'p': [1, 2]\n",
        "# }\n",
        "\n",
        "# # Initialize the KNN Classifier\n",
        "# knn = KNeighborsClassifier()\n",
        "\n",
        "# # Create a RandomizedSearchCV object\n",
        "# random_search = RandomizedSearchCV(knn, param_distributions=param_dist, n_iter=10, cv=5, n_jobs=-1)\n",
        "\n",
        "# # Train the model\n",
        "# random_search.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# # Print the best parameters found by RandomizedSearchCV\n",
        "# print(random_search.best_params_)\n",
        "\n",
        "# # Predict the test set results using the best model\n",
        "# y_pred = random_search.predict(X_test)\n",
        "\n",
        "# # Evaluate model accuracy\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "# print(f\"Model: {random_search.best_estimator_.__class__.__name__}, Accuracy: {accuracy}\")\n",
        "\n",
        "# # Evaluate model precision\n",
        "# precision = precision_score(y_test, y_pred, average='weighted')\n",
        "# print(f\"Model: {random_search.best_estimator_.__class__.__name__}, Precision: {precision}\")\n",
        "\n",
        "# # Evaluate model recall\n",
        "# recall = recall_score(y_test, y_pred, average='weighted')\n",
        "# print(f\"Model: {random_search.best_estimator_.__class__.__name__}, Recall: {recall}\")\n",
        "\n",
        "# # Evaluate model F1 score\n",
        "# f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "# print(f\"Model: {random_search.best_estimator_.__class__.__name__}, F1 Score: {f1}\")\n",
        "\n",
        "# # Print confusion matrix\n",
        "# conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "# print(f\"Confusion Matrix: \\n{conf_matrix}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
